# Preventi Flow: GestiÃ³n Inteligente de Documentos y Asistente Legal

## VisiÃ³n
Preventi Flow es una plataforma conversacional que integra IA, cumplimiento normativo y gestiÃ³n documental inteligente para organizaciones. Permite a usuarios y expertos:
- Solicitar, editar y guardar modelos de documentos legales y tÃ©cnicos.
- Rellenar campos editables guiados por el agente dentro del chat, no en formularios tradicionales.
- Guardar, descargar o compartir documentos en la biblioteca de su organizaciÃ³n.
- Calificar la calidad de las respuestas y modelos para mejorar el sistema.
- Integrarse con autenticaciÃ³n y panel organizacional Preventi Flow (https://preventiflow.com/).

## Plan de Trabajo Actual
1. **Modelos de Documento Inteligentes**
   - CreaciÃ³n y almacenamiento de plantillas base por expertos.
   - LibrerÃ­a centralizada con metadatos, campos editables y estilos.
2. **EdiciÃ³n Guiada en el Chat**
   - Renderizado de modelos con campos inline editables dentro de los globos del chat.
   - GuÃ­a paso a paso del agente para completar cada campo.
3. **Biblioteca Personal y Organizacional**
   - Guardado, descarga y comparticiÃ³n de documentos terminados.
   - AsociaciÃ³n a la organizaciÃ³n del usuario autenticado.
4. **CalificaciÃ³n de Respuestas y Modelos**
   - Box de 1 a 5 estrellas al final de cada respuesta.
   - Registro en Supabase para anÃ¡lisis y mejora continua.
5. **IntegraciÃ³n con AutenticaciÃ³n Preventi Flow**
   - Uso del sistema de login ya desplegado.
   - Acceso a funcionalidades avanzadas solo para usuarios autenticados.

## Normativa y Buenas PrÃ¡cticas
- UX: Conversational UI segÃºn Nielsen Norman Group.
- ProtecciÃ³n de datos: Ley 19.628 (Chile) y GDPR (UE).
- Seguridad: Control de acceso y autenticaciÃ³n robusta.

## Kit de Carpetas por OrganizaciÃ³n/Usuario (GestiÃ³n Documental)
Cada usuario puede crear mÃºltiples organizaciones. Para cada organizaciÃ³n se provisiona un kit de carpetas por defecto en el bucket de almacenamiento (Supabase). Estas carpetas base estÃ¡n protegidas contra eliminaciÃ³n:

- `01_reglamentos/`
- `02_afiliacion_y_seguros/`
- `03_comite_paritario/`
- `04_matriz_riesgos/`
- `05_capacitaciones/`
- `06_emergencias/`
- `07_accidentes_enfermedades/`
- `08_trabajadores/`
  - `08_trabajadores/trabajadores indirectos/` (protegida)
- `09_epp/`
- `10_fiscalizaciones/`
- `11_equipos_mantenimiento/`

Notas:
- En el futuro inmediato, las rutas se namespacen por organizaciÃ³n y usuario, p. ej.: `/{org_id}/{user_id}/01_reglamentos/`.
- El endpoint de borrado bloquea la eliminaciÃ³n de estas rutas base. Si se usa namespacing, la verificaciÃ³n deberÃ¡ considerar prefijos.

---

# Scraping Hub

Una aplicaciÃ³n web interna para gestionar, ejecutar y almacenar tareas de web scraping de forma centralizada.

## DescripciÃ³n

"Scraping Hub" es una soluciÃ³n completa para equipos que necesitan realizar scraping de contenido web de manera organizada y eficiente. La aplicaciÃ³n permite configurar trabajos de scraping, monitorear su progreso en tiempo real, y almacenar los resultados para su posterior anÃ¡lisis.

## CaracterÃ­sticas Principales

- ğŸš€ **Interfaz Moderna**: Construida con Next.js 14, TypeScript y Tailwind CSS
- ğŸ“Š **Dashboard**: Vista general de estadÃ­sticas y trabajos recientes
- ğŸ•¸ï¸ **Scraper Avanzado**: ConfiguraciÃ³n flexible de trabajos de scraping
- ğŸ“ˆ **Progreso en Tiempo Real**: Actualizaciones instantÃ¡neas mediante WebSockets
- ğŸ’¾ **Almacenamiento**: Guardado de resultados en Supabase (PostgreSQL)
- ğŸ¨ **UI Elegante**: Componentes accesibles con shadcn/ui
- âš¡ **Estrategias de Scraping**: MÃºltiples enfoques para diferentes tipos de sitios
- ğŸ›¡ï¸ **Seguridad**: ValidaciÃ³n de entrada y manejo seguro de datos

## TecnologÃ­as

### Frontend
- [Next.js 14](https://nextjs.org/) con App Router
- [TypeScript](https://www.typescriptlang.org/)
- [Tailwind CSS](https://tailwindcss.com/)
- [shadcn/ui](https://ui.shadcn.com/)
- [React](https://reactjs.org/)

### Backend
- [Netlify Functions](https://www.netlify.com/products/functions/)
- [Node.js](https://nodejs.org/)
- [Puppeteer](https://pptr.dev/)
- [Socket.IO](https://socket.io/)

### Base de Datos
- [Supabase](https://supabase.io/)
- [PostgreSQL](https://www.postgresql.org/)

## Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   WebSockets     â”‚    â”‚   Backend        â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   (Tiempo Real)  â”‚â—„â”€â”€â–ºâ”‚   (Netlify)      â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚   (Puppeteer)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   Base de Datos  â”‚
                      â”‚   (Supabase)     â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Requisitos del Sistema

- Node.js v18.17.0 o superior
- npm v9.0.0 o superior
- Git v2.13.0 o superior
- 8GB RAM mÃ­nimo (16GB recomendado)

## InstalaciÃ³n

### 1. Clonar el Repositorio
```bash
git clone https://github.com/tu-organizacion/scraping-hub.git
cd scraping-hub
```

### 2. Instalar Dependencias
```bash
npm install
```

### 3. Configurar Variables de Entorno
```bash
cp .env.example .env.local
```

Editar `.env.local` con tus credenciales de Supabase:

```bash
NEXT_PUBLIC_SUPABASE_URL=tu_project_url_de_supabase
NEXT_PUBLIC_SUPABASE_KEY=tu_anon_key_de_supabase
NEXT_PUBLIC_WEBSOCKET_URL=ws://localhost:3001
```

### 4. Configurar Base de Datos
Ejecutar el siguiente SQL en tu proyecto de Supabase:

```sql
CREATE TABLE resultados_scraping (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  estrategia_usada TEXT,
  urls_procesadas INTEGER,
  resultado_json JSONB
);

CREATE INDEX idx_resultados_scraping_created_at ON resultados_scraping(created_at);
CREATE INDEX idx_resultados_scraping_estrategia ON resultados_scraping(estrategia_usada);
```

## EjecuciÃ³n

### Modo de Desarrollo
```bash
# Iniciar servidor de desarrollo
npm run dev

# La aplicaciÃ³n estarÃ¡ disponible en http://localhost:3000
```

### Modo de ProducciÃ³n
```bash
# Construir la aplicaciÃ³n
npm run build

# Iniciar servidor de producciÃ³n
npm run start
```

## Estructura del Proyecto

```
scraping-hub/
â”œâ”€â”€ app/                    # PÃ¡ginas de Next.js App Router
â”‚   â”œâ”€â”€ dashboard/          # PÃ¡gina Dashboard
â”‚   â”œâ”€â”€ scraper/            # PÃ¡gina Scraper
â”‚   â””â”€â”€ resultados/         # PÃ¡gina Resultados
â”œâ”€â”€ components/             # Componentes React
â”‚   â”œâ”€â”€ ui/                 # Componentes shadcn/ui
â”‚   â”œâ”€â”€ layout/             # Componentes de layout
â”‚   â”œâ”€â”€ scraper/            # Componentes del scraper
â”‚   â””â”€â”€ results/            # Componentes de resultados
â”œâ”€â”€ lib/                    # LibrerÃ­as y utilidades
â”œâ”€â”€ functions/              # Funciones Netlify
â”œâ”€â”€ public/                 # Archivos estÃ¡ticos
â”œâ”€â”€ styles/                 # Estilos globales
â”œâ”€â”€ types/                  # Tipos TypeScript
â”œâ”€â”€ hooks/                  # Hooks personalizados
â”œâ”€â”€ utils/                  # Funciones de utilidad
â””â”€â”€ tests/                  # Pruebas
```

## Estrategias de Scraping

### Estrategia Universal
Para sitios web desconocidos, utiliza mÃºltiples enfoques:
- BÃºsqueda por selectores CSS comunes
- AnÃ¡lisis de etiquetas semÃ¡nticas
- ExtracciÃ³n del contenido del body
- Procesamiento de texto avanzado

### Estrategia LeyChile
Para bcn.cl/leychile con alta precisiÃ³n:
- Manejo automÃ¡tico de banners de cookies
- Acceso a contenido en iframes
- ExtracciÃ³n especÃ­fica de `div#textoNorma`
- OptimizaciÃ³n para leyes chilenas

## DocumentaciÃ³n Completa

Para una guÃ­a detallada de implementaciÃ³n, consulta los siguientes documentos:

1. [Plan de Desarrollo](SCRAPING_HUB_PLAN.md) - Arquitectura y planificaciÃ³n
2. [ImplementaciÃ³n del Backend](SCRAPING_HUB_BACKEND.md) - Funciones y scraping
3. [ImplementaciÃ³n del Frontend](SCRAPING_HUB_FRONTEND.md) - UI y componentes
4. [IntegraciÃ³n del Sistema](SCRAPING_HUB_INTEGRACION.md) - Conexiones y seguridad
5. [GuÃ­a de Inicio](SCRAPING_HUB_INICIO.md) - InstalaciÃ³n y ejecuciÃ³n

## Pruebas

### Pruebas Unitarias
```bash
npm run test
```

### Pruebas de IntegraciÃ³n
```bash
npm run test:integration
```

### Pruebas E2E
```bash
npm run test:e2e
```

## Despliegue

### Netlify
1. Conectar repositorio a Netlify
2. Configurar variables de entorno
3. El despliegue se realiza automÃ¡ticamente en cada push

### ConfiguraciÃ³n Recomendada de Netlify
```toml
[build]
  command = "next build"
  publish = ".next"

[[plugins]]
  package = "@netlify/plugin-nextjs"
```

## ContribuciÃ³n

1. Fork del repositorio
2. Crear rama de feature (`git checkout -b feature/NuevaFuncionalidad`)
3. Commit cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/NuevaFuncionalidad`)
5. Abrir Pull Request

## Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## Soporte

Para reportar problemas o solicitar nuevas funcionalidades, por favor abre un issue en el repositorio.

## Desarrollado Por

**Tu Nombre/OrganizaciÃ³n** - [tu-sitio-web.com](https://tu-sitio-web.com)

## Agradecimientos

- [Next.js Team](https://vercel.com/) por el excelente framework
- [shadcn](https://twitter.com/shadcn) por los componentes UI
- [Supabase Team](https://supabase.io/) por la plataforma de backend
- [Puppeteer Team](https://pptr.dev/) por la librerÃ­a de automatizaciÃ³n
